---
sidebar_position: 7
---

# マイクロサービスのトレードオフ

---

## 概要

マイクロサービスアーキテクチャの採用は、多くのトレードオフを伴います。本ドキュメントでは、パフォーマンス、整合性、複雑性、コストなど、主要なトレードオフを定量的に分析します。

---

## トレードオフの全体像

```
┌─────────────────────────────────────────┐
│    マイクロサービスで得るもの            │
├─────────────────────────────────────────┤
│ ✓ 独立したデプロイ                      │
│ ✓ 部分的なスケーリング                  │
│ ✓ 障害の分離                            │
│ ✓ 技術スタックの自由                    │
│ ✓ チームの自律性                        │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│    マイクロサービスで失うもの            │
├─────────────────────────────────────────┤
│ ❌ パフォーマンス（ネットワーク制約）    │
│ ❌ データ整合性（トランザクション）      │
│ ❌ シンプルさ（分散システムの複雑性）    │
│ ❌ デバッグの容易さ                      │
│ ❌ 開発初期の速度                        │
└─────────────────────────────────────────┘
```

---

## トレードオフ1: パフォーマンス

### レイテンシの増加

**プロセス内呼び出し（モノリス）**:
```
UserService.getUser(id)

コスト: < 1μs
実測: 0.01-0.1ms
```

**ネットワーク呼び出し（マイクロサービス）**:
```
HTTP GET /users/USER_ID

コスト内訳:
├─ TCP接続: 1-3ms
├─ HTTPヘッダー処理: 0.5ms
├─ リクエスト送信: 0.5ms
├─ サーバー処理: 5ms
├─ レスポンス受信: 0.5ms
└─ JSONパース: 0.5ms

合計: 8-12ms（同一データセンター内）

差: 80-1,200倍遅い
```

---

### N+1問題の深刻化

**シナリオ: 10ユーザーの注文履歴表示**

```
モノリス:
SELECT users, orders
FROM users
LEFT JOIN orders ON users.id = orders.user_id
WHERE users.id IN (1,2,...,10)

実行時間: 5-10ms

マイクロサービス（素朴な実装）:
for user in users:  # 10回ループ
    orders = GET /orders?user_id={user.id}  # 20ms × 10

実行時間: 200ms

差: 20-40倍遅い

最適化（バッチAPI）:
GET /orders?user_ids=1,2,...,10

実行時間: 30ms

差: 3-6倍遅い（改善されるが、依然として遅い）
```

---

## トレードオフ2: データ整合性

### ACIDトランザクション vs Saga

**モノリス: 単純なトランザクション**
```
送金処理:

BEGIN;
  UPDATE accounts SET balance = balance - 1000 WHERE id = 'A';
  UPDATE accounts SET balance = balance + 1000 WHERE id = 'B';
  INSERT INTO logs (...);
COMMIT;

保証: ACID
実装: 5行
テスト: 単体テストで完結
エラー時: 自動ロールバック

複雑度: 低
```

---

**マイクロサービス: Saga実装**
```
送金処理:

Saga Orchestrator:
  ↓
Step 1: Account Service: 口座A減額
  成功 → Step 2
  失敗 → 終了

Step 2: Account Service: 口座B増額
  成功 → Step 3
  失敗 → Compensate Step 1（口座A増額）

Step 3: Log Service: 記録
  成功 → 完了
  失敗 → Compensate Step 2, 1

さらに考慮:
├─ ネットワークタイムアウト
├─ 部分的な成功
├─ 補償トランザクションの失敗
├─ 冪等性の保証
└─ 状態の永続化

実装: 100-300行
テスト: 統合テスト、カオステスト必要
エラー時: 手動実装の補償ロジック

複雑度: 高（10-20倍）
```

---

### 整合性のレベル

```
モノリス:
強い整合性（Strong Consistency）
└─ 読み取り時点で最新の値が保証

マイクロサービス:
結果整合性（Eventual Consistency）
└─ 最終的には整合するが、遅延あり

具体例:
注文作成 → 在庫更新

モノリス:
T=0秒: 注文作成と在庫更新が同時完了

マイクロサービス:
T=0秒: 注文作成完了
T=2秒: イベント処理、在庫更新完了

この2秒間:
注文は存在するが、在庫は古い値
→ 二重販売のリスク

対策:
- 在庫引当の事前確認
- 楽観的ロック
- 整合性チェックの追加
→ さらに複雑化
```

---

## トレードオフ3: システムの複雑性

### 開発の複雑性

**モノリス**:
```
機能追加:
├─ コード追加（1ファイル）
├─ テスト追加
└─ デプロイ

ステップ数: 3
```

**マイクロサービス**:
```
機能追加（3サービスにまたがる）:

Service A:
├─ コード追加
├─ APIスキーマ更新
├─ 単体テスト
└─ デプロイ

Service B:
├─ Service A の新APIを呼び出すコード追加
├─ 単体テスト
├─ 統合テスト（Service A と）
└─ デプロイ

Service C:
├─ Service B の変更に対応
├─ テスト
└─ デプロイ

調整:
├─ API契約の合意
├─ デプロイ順序の調整
└─ バージョン互換性の確認

ステップ数: 15以上

複雑度: 5倍
```

---

### デバッグの複雑性

**モノリス**:
```
エラー発生:
  ↓
スタックトレース確認
  ↓
該当行を特定
  ↓
修正

時間: 10分-1時間
```

**マイクロサービス**:
```
エラー発生（どのサービス？）:
  ↓
Trace ID で検索
  ↓
5つのサービスのログを確認
  ↓
Service C で例外発生を確認
  ↓
Service C に渡されたデータを確認
  ↓
Service B のログを確認
  ↓
Service A が誤ったデータを返していた
  ↓
Service A のコード修正

時間: 1-3時間

複雑度: 3-5倍
```

---

## トレードオフ4: 運用コスト

### インフラコスト

**モノリス（小規模想定）**:
```
構成:
├─ アプリサーバー × 2（冗長化）
└─ データベース × 1

月額コスト例:
├─ EC2 t3.large × 2: $120
├─ RDS PostgreSQL: $80
└─ 合計: $200/月
```

**マイクロサービス（10サービス）**:
```
構成:
├─ 各サービス × 3レプリカ = 30 Pod
├─ データベース × 10
├─ メッセージブローカー（Kafka）
├─ API Gateway
├─ サービスメッシュ（Istio）
├─ 監視スタック（Prometheus、Jaeger）
└─ Kubernetes クラスター

月額コスト例:
├─ Kubernetes（EKS）: $150
├─ ワーカーノード × 5: $500
├─ RDS × 10: $800
├─ Kafka（MSK）: $300
├─ 監視ツール: $100
└─ 合計: $1,850/月

差: 約9倍

※規模により変動、大規模時は効率化
```

---

### 運用負荷

**モノリス**:
```
運用タスク:
├─ デプロイ（1アプリ）
├─ 監視（1プロセス）
├─ ログ確認（1箇所）
└─ バックアップ（1 DB）

担当: 1-2名で可能
```

**マイクロサービス**:
```
運用タスク:
├─ デプロイ（10サービス × 環境）
├─ 監視（10サービス + インフラ）
├─ ログ確認（10サービス、分散）
├─ バックアップ（10 DB）
├─ サービスメッシュ管理
├─ メッセージブローカー管理
└─ Kubernetes クラスター管理

担当: 3-5名必要（DevOpsチーム）

人件費: 3-5倍
```

---

## トレードオフ5: 開発速度

### 初期開発

**モノリス**:
```
プロジェクト開始から最初のリリースまで:

Week 1-4: 開発
Week 5-6: テスト
Week 7-8: デプロイ準備

期間: 8週間
シンプルな構成で高速
```

**マイクロサービス**:
```
プロジェクト開始から最初のリリースまで:

Week 1-2: アーキテクチャ設計
Week 3-4: インフラ構築（K8s、監視等）
Week 5-6: サービス間通信基盤
Week 7-10: 各サービス開発
Week 11-12: 統合テスト
Week 13-14: デプロイ

期間: 14週間

初期: 遅い（インフラ構築コスト）
```

---

### 継続的な開発

**モノリス**:
```
機能追加の速度:

初期: 高速
  ↓
コードベース増大
  ↓
後期: 低速（技術的負債、影響範囲の拡大）

グラフ:
速度 ↑ ╲
     │  ╲___
     │      ＼___
     └──────────→ 時間
```

**マイクロサービス**:
```
機能追加の速度:

初期: 低速（基盤構築）
  ↓
基盤確立
  ↓
後期: 高速維持（サービスが独立）

グラフ:
速度 ↑    ___________
     │   ／
     │  ／
     │ ／
     └──────────→ 時間

クロスポイント: 1-2年後
```

---

## トレードオフ6: テストの複雑性

### 単体テスト

**モノリス**:
```
テスト:
モック不要（同一プロセス）

@Test
public void testOrderCreation() {
    Order order = orderService.create(...);
    assertEquals(expected, order);
}

シンプル
```

**マイクロサービス**:
```
テスト:
外部サービスのモックが必要

@Test
public void testOrderCreation() {
    // Inventory Service をモック
    when(inventoryClient.check(...)).thenReturn(available);

    // Payment Service をモック
    when(paymentClient.charge(...)).thenReturn(success);

    Order order = orderService.create(...);
    assertEquals(expected, order);
}

複雑度: 2-3倍
```

---

### 統合テスト

**モノリス**:
```
アプリ起動 → テスト実行

環境:
- アプリケーション × 1
- データベース × 1

セットアップ: 簡単
```

**マイクロサービス**:
```
全サービス起動 → テスト実行

環境:
- 10サービス × それぞれ
- データベース × 10
- メッセージブローカー
- API Gateway

セットアップ:
Docker Compose または Kubernetes
数十のコンテナ起動

起動時間:
モノリス: 30秒
マイクロサービス: 3-5分

複雑度: 10倍
```

---

## トレードオフの定量比較

### 小規模システム（チーム5人、トラフィック低）

```
┌──────────────┬──────────┬──────────────┐
│ 観点         │ モノリス │ マイクロ     │
├──────────────┼──────────┼──────────────┤
│ 開発速度     │ ★★★★★ │ ★★         │
│ パフォーマンス│ ★★★★★ │ ★★★       │
│ 運用負荷     │ ★★★★★ │ ★           │
│ インフラコスト│ ★★★★★ │ ★★         │
│ スケーラビリティ│ ★★★ │ ★★★★     │
│ 障害分離     │ ★       │ ★★★★★   │
├──────────────┼──────────┼──────────────┤
│ 総合評価     │ 勝ち     │ 負け         │
└──────────────┴──────────┴──────────────┘

結論: モノリスが圧倒的に有利
```

---

### 大規模システム（チーム50人、トラフィック高）

```
┌──────────────┬──────────┬──────────────┐
│ 観点         │ モノリス │ マイクロ     │
├──────────────┼──────────┼──────────────┤
│ 開発速度     │ ★★      │ ★★★★     │
│ パフォーマンス│ ★★★   │ ★★★★     │
│ 運用負荷     │ ★★      │ ★★★       │
│ インフラコスト│ ★★★   │ ★★★★     │
│ スケーラビリティ│ ★★  │ ★★★★★   │
│ 障害分離     │ ★       │ ★★★★★   │
│ デプロイ頻度 │ ★       │ ★★★★★   │
│ チーム自律性 │ ★       │ ★★★★★   │
├──────────────┼──────────┼──────────────┤
│ 総合評価     │ 負け     │ 勝ち         │
└──────────────┴──────────┴──────────────┘

結論: マイクロサービスが有利
```

---

## 規模によるクロスポイント

```
┌─────────────────────────────────────────┐
│     総合的な開発効率                     │
├─────────────────────────────────────────┤
│ 効率↑                                   │
│     │ マイクロサービス                  │
│     │        ／‾‾‾‾‾‾‾‾              │
│     │      ／                           │
│     │    ／   ✕（クロスポイント）       │
│     │  ／    ／                         │
│     │／____／ モノリス                  │
│     │                                   │
│     └──────────────────→ 規模          │
│     小              大                   │
│  (5人、5サービス)  (50人、50サービス)   │
└─────────────────────────────────────────┘

クロスポイント:
- チーム: 15-20人
- サービス数: 10-15個
- この規模を超えたらマイクロサービス検討
```

---

## 意思決定のフレームワーク

### コスト・ベネフィット分析

**コスト（定量化）**:
```
パフォーマンス劣化:
レスポンスタイム 3倍 → ユーザー離脱率 +10%
→ 売上影響: -$X/月

インフラコスト増加:
$200 → $1,850/月
→ 増加: $1,650/月

開発速度低下（初期）:
8週 → 14週
→ 機会損失: $Y

運用人員:
2名 → 5名
→ 人件費: +$Z/月

総コスト: $X + $1,650 + $Y + $Z
```

**ベネフィット（定量化）**:
```
デプロイ頻度向上:
月1回 → 週1回
→ 機能追加速度 4倍
→ 売上機会: +$A/月

障害の分離:
全停止 → 部分停止
→ 可用性向上: 99% → 99.9%
→ 機会損失削減: $B/月

部分的スケーリング:
全体スケール → 必要部分のみ
→ インフラコスト削減（大規模時）: $C/月

チーム生産性:
並行開発可能
→ 開発速度: $D/月の価値

総ベネフィット: $A + $B + $C + $D
```

**判断**:
```
総ベネフィット > 総コスト
  ↓
マイクロサービス採用

総ベネフィット < 総コスト
  ↓
モノリス継続
```

---

## 実際の失敗例

### 失敗1: 小規模でマイクロサービス化

```
スタートアップ（チーム3人）:

判断:
「将来の拡張性のためマイクロサービス」

結果:
├─ インフラ構築に2ヶ月
├─ 本来の機能開発が遅延
├─ 複雑すぎて開発速度低下
├─ 資金ショート
└─ 失敗

教訓:
将来の拡張性 < 今の開発速度
小規模時はモノリスが正解
```

---

### 失敗2: パフォーマンスを軽視

```
メディアサイト:

マイクロサービス化:
記事表示に5サービス呼び出し
→ レスポンス: 200ms

競合サイト（モノリス）:
→ レスポンス: 30ms

結果:
ユーザー離脱率増加
→ PV 20%減少

対策:
一部をモノリスに戻す
→ レスポンス改善

教訓:
パフォーマンス要件を軽視しない
```

---

## 成功のパターン

### 段階的な採用

```
Phase 1: モノリス（0-1年目）
└─ 素早くMVP構築

Phase 2: Modular Monolith（1-2年目）
└─ モジュール境界を明確化
   将来の分離に備える

Phase 3: 選択的マイクロサービス化（2年目以降）
└─ 高負荷な部分のみ分離
   例: 画像処理、検索、通知

結果:
- 各フェーズで最適なアーキテクチャ
- リスク最小化
- スケールに応じた進化
```

---

### ハイブリッドアプローチ

```
Shopify の例:

コア機能: モノリス
├─ 商品管理
├─ 注文処理
└─ 決済

独立サービス:
├─ 検索（Elasticsearch、高負荷）
├─ 画像処理（重い処理）
├─ 通知（非同期）
└─ 分析（異なる技術スタック）

判断基準:
分離のメリット > ネットワークコスト
→ 分離

利点:
- コアはシンプル（モノリス）
- 必要な部分のみマイクロサービス
- バランスが良い
```

---

## デメリットを軽減する概念とパターン

### 1. 分散トレーシング

**デメリット: デバッグが困難**
```
問題:
リクエストが5つのサービスを横断
どこで遅延？どこでエラー？

分散トレーシングの概念:

各リクエストに一意のID（Trace ID）を付与
  ↓
全サービスがこのIDを引き継ぐ
  ↓
各サービスでの処理時間を記録（Span）
  ↓
Trace ID で全Spanを集約
  ↓
リクエストの経路と時間を可視化

┌──────────────────────────────────┐
│ Trace: abc-123                   │
├──────────────────────────────────┤
│ API Gateway:     50ms            │
│   ├─ Order Service:    180ms    │
│   │   ├─ DB Query:       50ms   │
│   │   └─ Inventory:      100ms ←遅い！
│   └─ Notification:      20ms    │
└──────────────────────────────────┘

効果:
ボトルネック特定が容易
デバッグ時間: 1-3時間 → 10-30分

仕組み:
HTTPヘッダーでTrace IDを伝播
各サービスがSpan情報を記録
中央で集約・可視化
```

---

### 2. 構造化ログと集中管理

**デメリット: ログが分散**
```
問題:
10サービス × 3レプリカ = 30箇所のログ

集中ログ管理の概念:

各サービス:
└─ 構造化ログ（JSON）出力
   {"trace_id": "abc-123", "service": "order", ...}
  ↓
ログ収集エージェント
  ↓
中央ストレージ（検索可能）
  ↓
Trace ID で検索
  ↓
関連する全ログを一括表示

効果:
分散していても、実質的には1箇所
モノリスと同等のログ調査が可能

重要なのは:
- 構造化（機械可読）
- Trace ID の統一
- 集中検索
```

---

### 3. Service Mesh（サイドカーパターン）

**デメリット: サービス間通信の実装が複雑**
```
問題:
各サービスで実装が必要:
├─ mTLS（暗号化通信）
├─ リトライロジック
├─ タイムアウト設定
├─ サーキットブレーカー
└─ メトリクス収集

Service Mesh の概念:

各Podに透過的なプロキシ（Sidecar）を配置
  ↓
全ての通信がプロキシ経由
  ↓
プロキシが自動的に:
├─ mTLS 処理
├─ リトライ
├─ タイムアウト
├─ メトリクス収集
└─ トレーシング

アプリケーションコード:
http://other-service/api
→ シンプルなHTTP呼び出しのまま

効果:
横断的関心事をインフラ層で解決
アプリは ビジネスロジックに集中
```

---

### 4. API Gateway パターン

**デメリット: クライアントが複数サービスを呼ぶ必要**
```
問題:
モバイルアプリが5サービスを直接呼び出し
→ ネットワーク往復 × 5
→ レイテンシ大

API Gateway の概念:

クライアント → API Gateway（単一エントリー）
                    ↓
    ┌───────────────┼───────────────┐
    ↓               ↓               ↓
  Service A     Service B       Service C
    ↓               ↓               ↓
API Gateway ← 結果を集約
    ↓
クライアント ← 1回のレスポンス

効果:
ネットワーク往復: 5回 → 1回
クライアント側の複雑性: 大幅削減
レイテンシ: 改善（並列処理可能）

さらに:
- 認証・認可を一箇所で
- レート制限
- レスポンス変換
```

---

### 5. Saga Orchestrator パターン

**デメリット: 分散トランザクションが複雑**
```
問題:
補償トランザクションの手動実装が複雑

Saga Orchestrator の概念:

中央のOrchestratorが状態を管理:

Orchestrator:
  ├─ ステップ1実行 → 成功を記録
  ├─ ステップ2実行 → 成功を記録
  ├─ ステップ3実行 → 失敗を記録
  └─ 補償実行（ステップ2、1を戻す）

状態:
データベースに永続化
障害時も復旧可能

効果:
- 補償ロジックの体系的管理
- リトライ・タイムアウトの統一的処理
- 状態の可視化

Choreography（イベント駆動）より:
- フローが明確
- デバッグが容易
```

---

### 6. CQRS + Event Sourcing

**デメリット: 複数DBにまたがるクエリができない**
```
問題:
注文情報（Order Service）
ユーザー情報（User Service）
→ JOINできない

CQRS の概念:

書き込み側（Command）:
各サービスが独立したDB
  ↓ イベント発行
読み取り側（Query）:
専用の非正規化DB
└─ 必要なデータを事前に結合

クエリ実行:
読み取り専用DBから高速取得
JOINの必要なし

トレードオフ:
✓ クエリパフォーマンス向上
❌ データ同期の複雑性
⚠ 結果整合性（数秒の遅延）

適用場面:
- 複雑な検索・集計が必要
- リアルタイム性は不要
```

---

### 7. 接続プールとキープアライブ

**デメリット: 接続確立のオーバーヘッド**
```
問題:
毎回TCP接続を確立
├─ 3-way handshake: 1-3ms
└─ 呼び出しごとに発生

接続プールの概念:

事前に接続を確保（プール）:
┌────────────────────┐
│ Connection Pool    │
│ ├─ Conn 1 (idle)   │
│ ├─ Conn 2 (in use) │
│ ├─ Conn 3 (idle)   │
│ └─ Conn 4 (in use) │
└────────────────────┘

リクエスト時:
プールから取得（即座）
使用後は返却（再利用）

効果:
接続確立コスト: 毎回 → 初回のみ
レイテンシ削減: 3ms削減/リクエスト

HTTP Keep-Alive:
同様の効果
TCP接続を再利用
```

---

### 8. バルクヘッド（隔壁）パターン

**デメリット: 障害の連鎖**
```
問題:
Service A が遅い
→ Service B のスレッドが詰まる
→ Service B も応答不能
→ 連鎖障害

バルクヘッドの概念:

Service B 内でリソースを分離:

┌─────────────────────────┐
│ Service B               │
├─────────────────────────┤
│ Service A 用スレッドプール│
│ (10スレッド、上限)      │
├─────────────────────────┤
│ Service C 用スレッドプール│
│ (10スレッド)            │
├─────────────────────────┤
│ その他の処理            │
│ (20スレッド)            │
└─────────────────────────┘

Service A が遅くても:
- A用の10スレッドのみ影響
- C用、その他は正常動作

効果:
障害の連鎖を防ぐ
部分的な機能低下で全停止を回避

船の隔壁と同じ原理:
一箇所に穴が開いても、
船全体は沈まない
```

---

### 9. サーキットブレーカー

**デメリット: 障害サービスへの無駄な呼び出し**
```
問題:
Service B が障害中
→ Service A が何度も呼び出し
→ タイムアウト待ち × N回
→ リソース浪費

サーキットブレーカーの概念:

状態管理:
CLOSED（正常） → OPEN（遮断） → HALF_OPEN（試行）

CLOSED:
通常通り呼び出し

エラー率が閾値超過（例: 5回連続失敗）:
  ↓
OPEN:
即座にエラー返却（呼び出さない）
リソース保護

一定時間後:
  ↓
HALF_OPEN:
1回だけ試行
  成功 → CLOSED に戻る
  失敗 → OPEN のまま

効果:
無駄な呼び出しを防ぐ
障害サービスへの負荷軽減
高速なフェイルファスト
```

---

### 10. 非正規化とデータ複製

**デメリット: サービス間のデータ結合が困難**
```
問題:
注文情報 + ユーザー情報 が必要
→ 2サービス呼び出し
→ レイテンシ増加

データ複製の概念:

User Service（マスター）
  ↓ ユーザー更新イベント
Order Service（ローカルコピー保持）

Order Service 内:
┌──────────────────────┐
│ orders テーブル      │
│ users_cache テーブル │← User情報のコピー
└──────────────────────┘

注文取得時:
ローカルでJOIN可能
ネットワーク呼び出し不要

トレードオフ:
✓ 読み取り高速化（20ms → 1ms）
❌ データ重複
⚠ 同期遅延（結果整合性）

適用条件:
- 更新頻度が低い
- リアルタイム性が不要
- 読み取り頻度が高い
```

---

## 概念の組み合わせ

### 総合的なデメリット軽減

```
マイクロサービスの主要デメリット:

1. デバッグ困難
   → 分散トレーシング
   → 構造化ログ

2. パフォーマンス低下
   → キャッシング
   → データ複製
   → 接続プール
   → gRPC/HTTP2

3. データ整合性
   → Saga Orchestrator
   → Event Sourcing
   → 結果整合性の受容

4. 障害の連鎖
   → サーキットブレーカー
   → バルクヘッド
   → タイムアウト設定

5. 運用複雑性
   → Service Mesh（横断的関心事の分離）
   → GitOps（自動化）
   → オートスケーリング

これらの概念を組み合わせることで:
デメリットを50-70%程度軽減可能

ただし:
完全には解消できない
モノリスより複雑なのは変わらない
```

---

## まとめ

### トレードオフの本質

```
マイクロサービス = 複雑性との交換

支払うコスト:
├─ パフォーマンス（ネットワーク）
├─ 整合性（分散トランザクション）
├─ シンプルさ（複雑性増加）
├─ インフラコスト
└─ 運用負荷

得られる価値:
├─ 独立したデプロイ
├─ スケーラビリティ
├─ 障害の分離
├─ 技術的自由
└─ チームの自律性

重要な問い:
「このコストを支払う価値があるか？」
```

### 判断のガイドライン

```
モノリスを選ぶべき:
- チーム < 10人
- サービス想定 < 5個
- トラフィック < 100 req/s
- 強い整合性が必要
- スタートアップ（ピボット可能性）

Modular Monolith を選ぶべき:
- チーム 10-20人
- 将来の拡張に備えたい
- まだマイクロサービスは早い

マイクロサービスを選ぶべき:
- チーム > 20人
- サービス想定 > 15個
- 部分的な高負荷
- 高可用性要求
- 組織が成熟（DevOps文化）

ハイブリッドを選ぶべき:
- 上記の中間
- 現実的な解が多い
```

---

## 参考リンク

- [MonolithFirst (Martin Fowler)](https://martinfowler.com/bliki/MonolithFirst.html)
- [Prime Video: Scaling up and reducing costs by 90%](https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90)
- [Shopify: Deconstructing the Monolith](https://shopify.engineering/deconstructing-monolith-designing-software-maximizes-developer-productivity)

**最終更新**: 2026-01-24
